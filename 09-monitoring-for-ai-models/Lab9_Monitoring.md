# üß™ Lab 9: Monitoreo de Modelos de IA

## üìå Descripci√≥n

En este laboratorio aprender√°s a instrumentar y monitorear tus aplicaciones de LLM utilizando **Langfuse**. Configurar√°s trazas, analizar√°s m√©tricas de costo y latencia, y realizar√°s experimentos de optimizaci√≥n y A/B testing para mejorar el rendimiento de tus modelos.

---

## üìã Ejercicio 1: Crear cuenta y configurar Langfuse

**Objetivo**: Configurar el entorno de monitoreo en la nube para registrar la actividad de tus aplicaciones.

### Pasos a seguir:

1. **Crear una cuenta**:
   - Ingresa a [Langfuse Cloud](https://cloud.langfuse.com/auth/sign-up).
   - Crea una cuenta nueva (puedes usar GitHub o Google).

2. **Generar API Keys**:
   - Ve al panel **Settings** ‚Üí **API Keys**.
   - Crea una nueva API Key.
   - Guarda las siguientes credenciales de forma segura:
     - `public_key` (empieza con `pk-`)
     - `secret_key` (empieza con `sk-`)
     - `base_url`

> ‚ö†Ô∏è **Nota**: No compartas las claves p√∫blicamente. Cada estudiante deber√° usar sus propias credenciales.

---

## üíª Ejercicio 2: Crear un proyecto Python

**Objetivo**: Instrumentar una aplicaci√≥n b√°sica para enviar trazas a Langfuse.

### Requisitos:

- Instalar dependencias necesarias (`langfuse`, `openai`).
- Inicializar el cliente de Langfuse y OpenAI.
- Ejecutar al menos **5 prompts** distintos.
- Verificar en la UI de Langfuse que aparecen los traces.

### Ejemplo de estructura:

```python
from langfuse import Langfuse
from langfuse.openai import openai
import os

# Configuraci√≥n de entorno (o usar .env)
# os.environ["LANGFUSE_PUBLIC_KEY"] = "pk-..."
# os.environ["LANGFUSE_SECRET_KEY"] = "sk-..."
# os.environ["LANGFUSE_HOST"] = "https://cloud.langfuse.com"

# Tu c√≥digo de generaci√≥n aqu√≠
completion = openai.chat.completions.create(
  name="test-chat",
  model="gpt-3.5-turbo",
  messages=[{"role": "user", "content": "¬øCu√°l es la capital de Francia?"}],
)
```

---

## üìä Ejercicio 3: An√°lisis de M√©tricas

**Objetivo**: Interpretar los datos recolectados en el dashboard para entender el comportamiento del modelo.

En la plataforma de Langfuse, identifica y reporta los siguientes datos:

- ‚è±Ô∏è **Latencia** por cada prompt.
- üî¢ **Tokens** de entrada y salida.
- üí∞ **Costo total estimado**.
- üìâ Identificar cu√°l fue el prompt **m√°s costoso**.
- üê¢ Identificar cu√°l fue el prompt **m√°s lento**.

---

## ‚ö° Ejercicio 4: Optimizaci√≥n

**Objetivo**: Mejorar la eficiencia de tus llamadas al LLM reduciendo costos o latencia.

### Pasos a seguir:

1. **Elegir un prompt ineficiente**: Selecciona uno de tus traces anteriores que haya sido costoso, lento o ambos.
2. **Optimizar el prompt**: Aplica al menos una de las siguientes estrategias:
   - Reducir longitud innecesaria.
   - Pedir respuestas m√°s breves.
   - Dividir la tarea en pasos m√°s peque√±os.
   - Reestructurar el requerimiento para mayor claridad.
   - Usar instrucciones m√°s directas.
3. **Re-ejecutar y Comparar**:
   - Ejecuta el prompt optimizado.
   - Compara **costos**, **tokens** y **latencia** con la versi√≥n original.
   - Verifica si la optimizaci√≥n fue efectiva analizando las m√©tricas.

---

## ‚öñÔ∏è Ejercicio 5: Evaluaciones con Ragas

**Objetivo**: Integrar m√©tricas de calidad (Ragas) en el monitoreo (Langfuse).

### Instrucciones:

1. **Referencia**: Toma el c√≥digo del **Lab 8** como base.
2. **Integraci√≥n**: Agrega o modifica el c√≥digo necesario para enviar los scores de evaluaci√≥n de Ragas a Langfuse.
3. **Verificaci√≥n**: Confirma que las m√©tricas est√°n siendo registradas correctamente en la secci√≥n **Scores > Analytics** de la UI de Langfuse.

---

## üìù Ejercicio 6: Prompt Management

**Objetivo**: Desacoplar los prompts del c√≥digo y gestionar versiones desde la plataforma.

1. **App de Consola**:
   - Crea un script en Python que permita al usuario hacer una pregunta de conocimiento general y elegir el **tono** deseado de la respuesta.
   - Crea **3 prompts** en Langfuse que establezcan diferentes tonos (ej. Formal, Explicativo, Sarc√°stico).
2. **Evaluaci√≥n Autom√°tica**:
   - Sin modificar el c√≥digo de la aplicaci√≥n, configura una evaluaci√≥n para que el LLM brinde una calificaci√≥n del **1 al 5** sobre la calidad de la respuesta generada.

---

## üß™ Ejercicio 7: A/B Testing de Prompts

**Objetivo**: Comparar emp√≠ricamente dos versiones de un prompt para determinar cu√°l funciona mejor.

1. **Configuraci√≥n**:
   - Crea y registra en Langfuse dos versiones diferentes de un mismo prompt.
   - Define para cada uno:
     - `nombre`
     - `prompt`
     - `version/labels`
2. **Ejecuci√≥n**:
   - Realiza al menos **10 llamadas** al LLM utilizando de forma aleatoria ambas versiones del prompt.
3. **An√°lisis**:
   - Analiza y compara los resultados en el dashboard de Langfuse para determinar el ganador.

---

## üéØ Criterios de Evaluaci√≥n

| Criterio | Excelente | Bueno | Satisfactorio |
|----------|-----------|-------|---------------|
| **Configuraci√≥n** | Traces completos, keys seguras, estructura limpia | Traces b√°sicos visibles | Configuraci√≥n m√≠nima, keys expuestas |
| **Optimizaci√≥n** | An√°lisis detallado pre/post, mejora clara documentada | Intento de optimizaci√≥n con datos | Cambio menor sin an√°lisis profundo |
| **Integraci√≥n Ragas** | Scores visibles y analizados en Langfuse | Scores visibles en Langfuse | Intento de integraci√≥n sin √©xito total |
| **Prompt Mgmt** | Uso fluido de prompts gestionados y versionados | Prompts creados y usados | Prompts hardcodeados o mal gestionados |

---

## üìö Recursos Recomendados

- **Langfuse Documentation**: [https://langfuse.com/docs](https://langfuse.com/docs)
- **Langfuse + Ragas Integration**: [https://langfuse.com/docs/scores/model-based-evals/ragas](https://langfuse.com/docs/scores/model-based-evals/ragas)
- **OpenAI Cookbook**: [https://cookbook.openai.com/](https://cookbook.openai.com/)

---

## üöÄ Tips para el √âxito

- üîê **Seguridad**: Nunca subas tus API Keys al repositorio. Usa variables de entorno (`.env`) y `.gitignore`.
- üè∑Ô∏è **Etiquetas**: Usa tags en Langfuse para filtrar tus experimentos f√°cilmente.
- üìâ **Costos**: Mant√©n un ojo en el uso de tokens para no exceder tu presupuesto mientras haces pruebas.