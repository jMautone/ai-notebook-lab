{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kidGzNtdmsxl"
      },
      "source": [
        "# Laboratorio 2: Bases de Datos Vectoriales\n",
        "\n",
        "En este ejercicio explorar√°s c√≥mo aprovechar modelos de embedding para transformar datos textuales en representaciones vectoriales, almacenarlas en una base de datos vectorial y realizar b√∫squedas sem√°nticas.\n",
        "\n",
        "Antes de comenzar el laboratorio, debes configurar el entorno de ejecuci√≥n de Colab para usar GPU en el c√≥mputo de los embeddings locales. Para ello, ve a la secci√≥n inferior de Colab y cambia el runtime a una GPU T4:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgzeMj3cucHv"
      },
      "source": [
        "A lo largo de este laboratorio realizar√°s las siguientes tareas:\n",
        "\n",
        "1. **Extracci√≥n de informaci√≥n de un archivo CSV**: Cargar√°s datos desde un archivo CSV.\n",
        "2. **Creaci√≥n de embeddings**: Emplear√°s un modelo de embedding pre-entrenado para convertir la informaci√≥n en vectores (embeddings).\n",
        "3. **Almacenamiento en una BBDD vectorial**: Almacenar√°s los embeddings generados en un √≠ndice.\n",
        "4. **B√∫squedas sem√°nticas**: Realizar√°s b√∫squedas sem√°nticas en el √≠ndice para encontrar informaci√≥n relevante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-xGTv3OMv0L"
      },
      "source": [
        "# Pinecone\n",
        "\n",
        "A continuaci√≥n trabajar√°s con Pinecone, una base de datos vectorial especializada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b20a82a"
      },
      "source": [
        "## Parte 1: Extracci√≥n de informaci√≥n de un archivo CSV\n",
        "\n",
        "Carga el archivo `home_depot_data.csv` (disponible en https://www.kaggle.com/datasets/thedevastator/the-home-depot-products-dataset) en un DataFrame de pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG197c4KVBJB"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ca6e882e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('home_depot_data.csv')\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6a3a625"
      },
      "source": [
        "### Preparar los datos para la generaci√≥n de embeddings\n",
        "\n",
        "Selecciona las columnas de texto relevantes del DataFrame que ser√°n utilizadas para generar los embeddings. En caso necesario, combina varias columnas (por ejemplo, nombre del producto y descripci√≥n) en un solo campo de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "39321df6"
      },
      "outputs": [],
      "source": [
        "# Seleccionar columnas relevantes y combinarlas en un solo campo de texto\n",
        "df['text'] = df[['title', 'description', 'price', 'currency']].fillna('').apply(\n",
        "    lambda x: f\"{x['title']} | {x['description']} | Price: {x['price']} {x['currency']}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Mostrar las primeras filas del nuevo campo\n",
        "df[['title', 'description', 'price', 'currency', 'text']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c890d720"
      },
      "source": [
        "## Parte 2: Carga del modelo de embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxeaU_6OFYGD"
      },
      "source": [
        "Carga el modelo de embeddings `all-MiniLM-L6-v2` utilizando la librer√≠a `sentence-transformers`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5JqXPeKFcgR"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BelLOCGmFjBA"
      },
      "source": [
        "Define una funci√≥n que, dado un texto, retorne su vector de embeddings en forma de lista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51ZLCMNdFluk"
      },
      "outputs": [],
      "source": [
        "def get_embedding(text):\n",
        "  \"\"\"\n",
        "  Generates an embedding vector for a given text using the loaded model.\n",
        "\n",
        "  Args:\n",
        "    text: The input text string.\n",
        "\n",
        "  Returns:\n",
        "    A list representing the embedding vector.\n",
        "  \"\"\"\n",
        "  embedding = model.encode(text).tolist()\n",
        "  return embedding\n",
        "\n",
        "# Example usage:\n",
        "example_text = \"This is an example sentence.\"\n",
        "embedding = get_embedding(example_text)\n",
        "print(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBXZfhj-HR7n"
      },
      "source": [
        "## Parte 3: Creaci√≥n del √≠ndice en Pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aff5646"
      },
      "source": [
        "En esta secci√≥n deber√°s establecer una conexi√≥n a tu cuenta de Pinecone utilizando tu API KEY. Para esto tendr√°s que crearte una cuenta en Pinecone: https://www.pinecone.io/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2ecdnkJFrkz"
      },
      "source": [
        "Inicializa Pinecone utilizando la clave de API guardada en `userdata`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyFICY0kFIXS"
      },
      "outputs": [],
      "source": [
        "# 1. Instalar la biblioteca de Pinecone\n",
        "!pip install -q pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fC5nLaw5B0I5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pinecone import Pinecone\n",
        "from google.colab import userdata\n",
        "\n",
        "# 2. Intentar obtener la clave de API desde los Secretos de Colab\n",
        "try:\n",
        "    PINECONE_API_KEY = userdata.get('PCONE_TOKEN')\n",
        "\n",
        "    if PINECONE_API_KEY is None:\n",
        "        raise ValueError(\"No se encontr√≥ la clave 'PCONE_TOKEN' en los Secretos de Colab.\\n\"\n",
        "                         \"Por favor, ve al panel üîë (Secretos) y a√±√°dela.\")\n",
        "\n",
        "    # 3. Inicializar el cliente de Pinecone\n",
        "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "    print(\"‚úÖ ¬°Conexi√≥n con Pinecone establecida exitosamente!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error al conectar o inicializar Pinecone: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI-14gRYF-aV"
      },
      "source": [
        "Crea un √≠ndice en Pinecone con la dimensi√≥n correspondiente al modelo y con la m√©trica `cosine`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Rt_6c0d-F_Ft"
      },
      "outputs": [],
      "source": [
        "# Importamos la clase ServerlessSpec, que es la requerida para el plan gratuito actual\n",
        "from pinecone import ServerlessSpec\n",
        "\n",
        "# --- 1. Definici√≥n de par√°metros ---\n",
        "index_name = \"home-depot-embeddings\"\n",
        "dimension = 384\n",
        "metric = \"cosine\"\n",
        "\n",
        "# --- 2. Par√°metros para el plan Serverless (Gratuito) ---\n",
        "cloud_provider = \"aws\"\n",
        "region_name = \"us-east-1\"\n",
        "\n",
        "try:\n",
        "    # --- 3. Comprobar si el √≠ndice ya existe ---\n",
        "    if index_name not in pc.list_indexes().names():\n",
        "\n",
        "        print(f\"Creando el √≠ndice Serverless '{index_name}' en {cloud_provider}:{region_name}...\")\n",
        "\n",
        "        # --- 4. Crear la especificaci√≥n Serverless ---\n",
        "        serverless_spec = ServerlessSpec(\n",
        "            cloud=cloud_provider,    # 'aws'\n",
        "            region=region_name       # 'us-east-1'\n",
        "        )\n",
        "\n",
        "        # --- 5. Crear el √≠ndice, pasando la especificaci√≥n al argumento 'spec' ---\n",
        "        pc.create_index(\n",
        "            name=index_name,\n",
        "            dimension=dimension,\n",
        "            metric=metric,\n",
        "            spec=serverless_spec     # <--- CLAVE: Pasamos el objeto ServerlessSpec\n",
        "        )\n",
        "        print(f\"‚úÖ ¬°√çndice Serverless '{index_name}' creado con dimensi√≥n {dimension} y m√©trica '{metric}'!\")\n",
        "\n",
        "    else:\n",
        "        # --- 6. Si ya existe, solo informa ---\n",
        "        print(f\"El √≠ndice '{index_name}' ya existe. No se realizaron cambios.\")\n",
        "\n",
        "    # --- 7. Conectarse al √≠ndice y mostrar estad√≠sticas ---\n",
        "    index = pc.Index(index_name)\n",
        "    print(\"\\nEstad√≠sticas del √≠ndice (para confirmar conexi√≥n):\")\n",
        "    print(index.describe_index_stats())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Ocurri√≥ un error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEA_xoSDHWg6"
      },
      "source": [
        "## Parte 4: Carga del √≠ndice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8zrW5a-B6si"
      },
      "source": [
        "Implementa el c√≥digo necesario para recorrer los datos del DataFrame, generar los embeddings correspondientes y realizar la inserci√≥n de la informaci√≥n en el √≠ndice creado previamente. Debes utilizar un esquema de procesamiento por lotes para optimizar la carga."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otNpw6Bv7Wui"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm.auto import tqdm # Importamos tqdm para mostrar una barra de progreso\n",
        "\n",
        "# --- 1. Configuraci√≥n de la Carga por Lotes ---\n",
        "BATCH_SIZE = 100\n",
        "index_name = \"home-depot-embeddings\" # Nombre del √≠ndice\n",
        "# Asumimos que 'index' ya est√° definido (ej: index = pc.Index(index_name))\n",
        "\n",
        "# --- 2. Preparaci√≥n de los datos ---\n",
        "# 2.1 Generamos una columna de IDs √∫nica (basada en el √≠ndice del DataFrame)\n",
        "if 'id' not in df.columns:\n",
        "    df['id'] = df.index.astype(str)\n",
        "\n",
        "# 2.2 Extraemos las columnas necesarias\n",
        "texts = df['text'].tolist()\n",
        "ids = df['id'].tolist()\n",
        "\n",
        "print(f\"Total de registros a procesar: {len(df)}\")\n",
        "\n",
        "# --- 3. Proceso de Inserci√≥n por Lotes ---\n",
        "# Inicializamos la barra de progreso de tqdm\n",
        "for i in tqdm(range(0, len(df), BATCH_SIZE)):\n",
        "    # Definir el lote actual\n",
        "    i_end = min(i + BATCH_SIZE, len(df))\n",
        "    batch_df = df.iloc[i:i_end] # Usamos el sub-DataFrame para acceder a todas las columnas\n",
        "\n",
        "    batch_ids = batch_df['id'].tolist()\n",
        "    batch_texts = batch_df['text'].tolist()\n",
        "\n",
        "    # --- A. Generar Embeddings ---\n",
        "    # Generaci√≥n eficiente de embeddings para todo el lote\n",
        "    embeddings = model.encode(batch_texts).tolist()\n",
        "\n",
        "    # --- B. Formatear para Pinecone (ID, Vector, Metadata) ---\n",
        "    vectors_to_upload = []\n",
        "\n",
        "    # Iteramos sobre las filas del lote\n",
        "    for idx, row in batch_df.iterrows():\n",
        "        # Capturamos la metadata relevante del DataFrame\n",
        "        metadata = {\n",
        "            \"title\": row['title'],\n",
        "            \"description\": row['description'],\n",
        "            \"price\": row['price'],\n",
        "            \"currency\": row['currency'],\n",
        "            \"combined_text\": row['text'] # El texto combinado es √∫til para depuraci√≥n\n",
        "        }\n",
        "\n",
        "        # El formato es (id, vector_lista, metadata_diccionario)\n",
        "        vectors_to_upload.append((\n",
        "            row['id'],\n",
        "            embeddings[idx - i], # Usamos el √≠ndice relativo al lote para obtener el embedding\n",
        "            metadata\n",
        "        ))\n",
        "\n",
        "    # --- C. Subir el Lote a Pinecone ---\n",
        "    try:\n",
        "        index.upsert(vectors=vectors_to_upload)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al subir el lote {i} a {i_end}: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Proceso de carga de datos finalizado.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66d36eb7"
      },
      "source": [
        "### Verificaci√≥n de datos en el √≠ndice\n",
        "\n",
        "Verifica las estad√≠sticas del √≠ndice para asegurarte de que los datos se hayan cargado correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "122d103c"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "print(\"\\n--- Verificaci√≥n del √çndice ---\")\n",
        "print(index.describe_index_stats())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7367271"
      },
      "source": [
        "### B√∫squeda sem√°ntica\n",
        "\n",
        "Realiza consultas al √≠ndice utilizando consultas del estilo `\"best tool for repairing walls\"` y muestra los resultados obtenidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5450b7a2"
      },
      "outputs": [],
      "source": [
        "# Asumimos que 'model' (SentenceTransformer) e 'index' (Pinecone Index) est√°n definidos.\n",
        "\n",
        "# --- 1. Definici√≥n de la Consulta ---\n",
        "query_text = \"best tool for repairing walls\"\n",
        "top_k_results = 5 # Cu√°ntos resultados m√°s similares queremos ver\n",
        "\n",
        "print(f\"B√∫squeda Sem√°ntica para: '{query_text}'\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- 2. Generar el Vector de Consulta ---\n",
        "# Usamos el mismo modelo para generar el embedding de la pregunta\n",
        "query_vector = model.encode(query_text).tolist()\n",
        "\n",
        "# --- 3. Consultar a Pinecone ---\n",
        "# Usamos el m√©todo index.query()\n",
        "results = index.query(\n",
        "    vector=query_vector,\n",
        "    top_k=top_k_results,\n",
        "    include_metadata=True # Esto es clave para obtener la informaci√≥n original\n",
        ")\n",
        "\n",
        "# --- 4. Mostrar los Resultados ---\n",
        "if results.matches:\n",
        "    print(f\"Se encontraron {len(results.matches)} resultados:\")\n",
        "\n",
        "    # Recorremos cada resultado encontrado por Pinecone\n",
        "    for i, match in enumerate(results.matches):\n",
        "        score = match.score\n",
        "        metadata = match.metadata\n",
        "\n",
        "        print(f\"\\nResultado {i+1} (Score: {score:.4f}):\")\n",
        "        print(f\"  T√≠tulo: {metadata.get('title', 'N/A')}\")\n",
        "        print(f\"  Precio: {metadata.get('price', 'N/A')} {metadata.get('currency', '')}\")\n",
        "        print(f\"  Descripci√≥n: {metadata.get('description', 'N/A')[:100]}...\")\n",
        "        # print(f\"  Texto Completo: {metadata.get('combined_text', 'N/A')}\") # Descomentar si quieres ver el texto combinado\n",
        "else:\n",
        "    print(\"No se encontraron coincidencias en el √≠ndice.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee593c10"
      },
      "source": [
        "# FAISS\n",
        "\n",
        "Realiza una pr√°ctica de b√∫squeda sem√°ntica utilizando FAISS y un dataset del sitio web https://www.kaggle.com/datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0ccb00e"
      },
      "source": [
        "## Parte 5: Cargar el nuevo dataset\n",
        "\n",
        "Carga el archivo en un DataFrame de pandas.\n",
        "\n",
        "**Ejemplo elegido**: https://www.kaggle.com/datasets/ahmeduzaki/global-earthquake-tsunami-risk-assessment-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXX5MnBQ9_yt"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dee6bb31"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('earthquake_data_tsunami.csv')\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a85c7abc"
      },
      "source": [
        "### Preparar los datos para la generaci√≥n de embeddings\n",
        "\n",
        "Selecciona las columnas de texto relevantes del nuevo DataFrame que ser√°n utilizadas para generar los embeddings. Combina las columnas necesarias en un solo campo de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8abf286"
      },
      "outputs": [],
      "source": [
        "# Preparar un √∫nico campo de texto por fila (sin depender de locales del sistema)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Asegurar tipos num√©ricos\n",
        "cols = ['magnitude','cdi','mmi','sig','nst','dmin','gap','depth',\n",
        "        'latitude','longitude','Year','Month','tsunami']\n",
        "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Diccionarios auxiliares\n",
        "tsunami_map = {1: 's√≠', 0: 'no'}\n",
        "mes_es = {1:'enero',2:'febrero',3:'marzo',4:'abril',5:'mayo',6:'junio',\n",
        "          7:'julio',8:'agosto',9:'septiembre',10:'octubre',11:'noviembre',12:'diciembre'}\n",
        "\n",
        "# Nombre de mes sin usar locale (evita errores en Colab)\n",
        "df['mes_nombre'] = df['Month'].round().astype('Int64').map(mes_es).fillna('desconocido')\n",
        "\n",
        "# Construir el texto por fila, robusto a NaNs\n",
        "def fila_a_texto(r):\n",
        "    fmt = lambda v, ndec=0: (f\"{v:.{ndec}f}\" if pd.notna(v) else \"NA\")\n",
        "    entero = lambda v: (str(int(v)) if pd.notna(v) else \"NA\")\n",
        "    return (\n",
        "        f\"Terremoto de magnitud {fmt(r.magnitude,1)} \"\n",
        "        f\"(MMI {entero(r.mmi)}, se√±al {entero(r.sig)}). \"\n",
        "        f\"Profundidad {fmt(r.depth,0)} km. \"\n",
        "        f\"Ubicaci√≥n lat {fmt(r.latitude,4)}, lon {fmt(r.longitude,3)}. \"\n",
        "        f\"Fecha {entero(r.Year)}-{entero(r.Month)} ({r.mes_nombre}). \"\n",
        "        f\"Estaciones {entero(r.nst)}, gap {fmt(r.gap,1)}, dmin {fmt(r.dmin,3)}. \"\n",
        "        f\"Tsunami: {tsunami_map.get(int(r.tsunami) if pd.notna(r.tsunami) else -1, 'desconocido')}.\"\n",
        "    )\n",
        "\n",
        "df['text_for_embedding'] = df.apply(fila_a_texto, axis=1)\n",
        "\n",
        "# DataFrame listo para embeddings\n",
        "df_embeddings = df[['text_for_embedding']].copy()\n",
        "display(df_embeddings.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4b952c"
      },
      "source": [
        "## Parte 6: Generar embeddings\n",
        "\n",
        "Aplica la funci√≥n para generar los embeddings del texto preparado en el paso anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bae5f85c"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Cargar modelo de embeddings (compacto y r√°pido)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Convertir la columna de texto a lista\n",
        "texts = df['text_for_embedding'].astype(str).tolist()\n",
        "\n",
        "# Generar embeddings normalizados (para usar luego similitud coseno con FAISS)\n",
        "embeddings = model.encode(\n",
        "    texts,\n",
        "    batch_size=64,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True,\n",
        "    normalize_embeddings=True\n",
        ").astype('float32')\n",
        "\n",
        "# Mostrar forma del array resultante\n",
        "print(\"Embeddings generados con forma:\", embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d61f9fd"
      },
      "source": [
        "## Parte 7: Crear un √≠ndice FAISS\n",
        "\n",
        "Inicializa un √≠ndice FAISS con la dimensi√≥n correcta para los embeddings generados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLvxMa5JLbmI"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2928a618"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Obtener la dimensi√≥n de los embeddings generados\n",
        "dimension = embeddings.shape[1]\n",
        "print(f\"Dimensi√≥n de los embeddings: {dimension}\")\n",
        "\n",
        "# Crear el √≠ndice FAISS (IndexFlatIP para similitud coseno)\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "print(\"√çndice FAISS creado correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ecd241a"
      },
      "source": [
        "### Agregar embeddings al √≠ndice FAISS\n",
        "\n",
        "Agrega los embeddings generados al √≠ndice FAISS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9e8e7d9"
      },
      "outputs": [],
      "source": [
        "# Agregar los embeddings generados al √≠ndice FAISS\n",
        "index.add(embeddings)\n",
        "\n",
        "# Verificar cu√°ntos vectores contiene el √≠ndice\n",
        "print(f\"Embeddings agregados al √≠ndice. Total de vectores: {index.ntotal}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b26b8939"
      },
      "source": [
        "### Realizar b√∫squedas sem√°nticas en FAISS\n",
        "\n",
        "Realiza consultas al √≠ndice FAISS utilizando consultas de texto y muestra los resultados obtenidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d91983a2"
      },
      "outputs": [],
      "source": [
        "# Realizar b√∫squedas sem√°nticas en FAISS usando consultas de texto\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 2) Funci√≥n para buscar en el √≠ndice FAISS\n",
        "def buscar_faiss(query_text, k=5):\n",
        "    \"\"\"\n",
        "    Genera el embedding de la consulta y busca los k m√°s similares en el √≠ndice FAISS.\n",
        "    Retorna un DataFrame con resultados y los puntajes de similitud.\n",
        "    \"\"\"\n",
        "    # Generar embedding normalizado de la consulta (para similitud coseno con IndexFlatIP)\n",
        "    q_vec = model.encode([query_text], normalize_embeddings=True, convert_to_numpy=True).astype('float32')\n",
        "\n",
        "    # Consultar FAISS\n",
        "    scores, idxs = index.search(q_vec, k)  # scores = producto interno (‚âà coseno)\n",
        "    idxs = idxs[0]\n",
        "    scores = scores[0]\n",
        "\n",
        "    # Armar tabla de resultados (join con df original)\n",
        "    res = df.iloc[idxs].copy()\n",
        "    res = res.assign(\n",
        "        rank=np.arange(1, len(idxs)+1),\n",
        "        score=np.round(scores, 4)\n",
        "    )[['rank','score','text_for_embedding','magnitude','Year','Month','latitude','longitude']]\n",
        "    res = res.rename(columns={'text_for_embedding':'texto'})\n",
        "    return res\n",
        "\n",
        "# 3) Ejemplos de consulta (puedes cambiar 'consulta' y 'k' a gusto)\n",
        "consulta = \"terremoto de magnitud 7 con tsunami\"\n",
        "resultados = buscar_faiss(consulta, k=5)\n",
        "\n",
        "# 4) Mostrar resultados\n",
        "print(f\"Consulta: {consulta}\\n\")\n",
        "display(resultados)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
