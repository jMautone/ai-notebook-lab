import os
import json
import sys
from typing import Dict, List
from openai import OpenAI
from dotenv import load_dotenv
import pandas as pd
import matplotlib.pyplot as plt

# Cargar variables de entorno
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("‚ö†Ô∏è OPENAI_API_KEY no configurada. Crea un archivo .env")

# ============================================================================
# EJERCICIO 1: Crear Dataset Propio
# ============================================================================

def create_custom_dataset() -> Dict[str, List[str]]:
    """
    Crea un dataset de evaluaci√≥n con al menos 5 pares de 
    (pregunta, contexto, respuesta de referencia)
    
    Requisitos cumplidos:
    ‚úÖ M√≠nimo 5 pares de (pregunta, contexto, respuesta de referencia)
    ‚úÖ Temas variados: Historia, Biolog√≠a, Ciencia, Tecnolog√≠a
    ‚úÖ Contexto detallado y suficiente
    ‚úÖ Respuestas de referencia precisas y completas
    """
    dataset = {
        "questions": [
            "¬øCu√°l fue el impacto de la Revoluci√≥n Industrial en la sociedad?",
            "¬øCu√°l es el proceso de fotos√≠ntesis en las plantas?",
            "¬øQu√© es el cambio clim√°tico y cu√°les son sus causas principales?",
            "¬øCu√°l fue el papel de Ada Lovelace en la historia de la inform√°tica?",
            "¬øCu√°les son los beneficios del ejercicio regular para la salud?"
        ],
        "contexts": [
            # Contexto para pregunta 1 - Historia
            [
                "La Revoluci√≥n Industrial (1760-1840) fue un per√≠odo de transformaci√≥n "
                "econ√≥mica y social que comenz√≥ en Gran Breta√±a. Marc√≥ el cambio de econom√≠as "
                "agr√≠colas a industriales mediante la mecanizaci√≥n de la manufactura. "
                "Provoc√≥ la migraci√≥n masiva de trabajadores rurales a ciudades, creando "
                "la clase obrera moderna. Aunque aument√≥ la producci√≥n de bienes, tambi√©n "
                "gener√≥ condiciones laborales precarias, contaminaci√≥n ambiental y desigualdad social. "
                "El sistema capitalista moderno surgi√≥ de este per√≠odo."
            ],
            # Contexto para pregunta 2 - Biolog√≠a
            [
                "La fotos√≠ntesis es el proceso mediante el cual las plantas convierten "
                "luz solar, agua y di√≥xido de carbono en glucosa y ox√≠geno. Ocurre "
                "principalmente en las hojas, en estructuras llamadas cloroplastos. "
                "El proceso tiene dos fases: la reacci√≥n luminosa (en la membrana de tilacoides) "
                "donde se genera ATP y NADPH usando energ√≠a de la luz, y el ciclo de Calvin "
                "(en el estroma) donde se sintetiza la glucosa a partir del CO2. "
                "Es fundamental para la vida en la Tierra pues produce ox√≠geno y alimento."
            ],
            # Contexto para pregunta 3 - Ciencia
            [
                "El cambio clim√°tico es el aumento a largo plazo de las temperaturas globales "
                "principalmente debido a las actividades humanas. Las causas principales incluyen: "
                "emisiones de gases de efecto invernadero (CO2, metano, N2O) por quema de combustibles f√≥siles, "
                "deforestaci√≥n, ganader√≠a intensiva e industria manufacturera. Estos gases atrapan calor en la atm√≥sfera "
                "mediante el efecto invernadero. Las consecuencias incluyen aumento del nivel del mar, "
                "eventos clim√°ticos extremos m√°s frecuentes, extinci√≥n de especies y disrupciones en la producci√≥n agr√≠cola. "
                "Las evidencias cient√≠ficas muestran que el 97% de los climat√≥logos est√°n de acuerdo."
            ],
            # Contexto para pregunta 4 - Tecnolog√≠a/Historia
            [
                "Ada Lovelace (1815-1852) fue una matem√°tica inglesa pionera en computaci√≥n. "
                "Trabaj√≥ con Charles Babbage en su M√°quina Anal√≠tica, una precursora de las "
                "computadoras modernas. En 1843 escribi√≥ el primer algoritmo pensado para ser "
                "procesado por una m√°quina, gan√°ndose el t√≠tulo de 'primer programador del mundo'. "
                "Sus notas sobre la m√°quina fueron m√°s extensas que el art√≠culo original de Babbage, "
                "demostrando una comprensi√≥n profunda de la l√≥gica computacional que anticip√≥ conceptos "
                "de programaci√≥n modernos (como loops y funciones) m√°s de un siglo antes de que existieran "
                "computadoras electr√≥nicas reales."
            ],
            # Contexto para pregunta 5 - Salud/Ciencia
            [
                "El ejercicio regular proporciona numerosos beneficios para la salud f√≠sica y mental. "
                "Mejora la funci√≥n cardiovascular incrementando la capacidad del coraz√≥n y reduciendo la presi√≥n arterial, "
                "aumenta la resistencia muscular y flexibilidad, ayuda a mantener un peso saludable y reduce el riesgo de "
                "enfermedades cr√≥nicas como diabetes tipo 2, hipertensi√≥n arterial y algunos c√°nceres. "
                "Psicol√≥gicamente, el ejercicio reduce estr√©s y depresi√≥n, mejora el estado de √°nimo mediante la liberaci√≥n "
                "de endorfinas, fortalece la funci√≥n cognitiva y reduce el riesgo de demencia. "
                "Las directrices de salud mundial recomiendan 150 minutos de actividad aer√≥bica moderada por semana "
                "para adultos, complementados con ejercicios de resistencia."
            ]
        ],
        "answers": [
            # Respuesta de referencia 1
            "La Revoluci√≥n Industrial transform√≥ la sociedad mediante la mecanizaci√≥n de la manufactura, "
            "provocando la migraci√≥n rural-urbana y la creaci√≥n de la clase obrera moderna. Aunque aument√≥ significativamente "
            "la producci√≥n de bienes y contribuy√≥ al surgimiento del capitalismo moderno, tambi√©n gener√≥ condiciones laborales precarias, "
            "contaminaci√≥n ambiental y una brecha de desigualdad socioecon√≥mica entre propietarios de f√°bricas y trabajadores.",
            
            # Respuesta de referencia 2
            "La fotos√≠ntesis es el proceso donde las plantas convierten luz solar, agua y CO2 en glucosa y ox√≠geno. "
            "Ocurre en dos fases: la reacci√≥n luminosa genera ATP y NADPH usando energ√≠a de la luz, mientras que el ciclo de Calvin "
            "sintetiza glucosa a partir del CO2. Es esencial para producir ox√≠geno respirable y alimento para la mayor√≠a de los organismos vivos.",
            
            # Respuesta de referencia 3
            "El cambio clim√°tico es el aumento de temperaturas globales causado principalmente por emisiones humanas de gases "
            "de efecto invernadero (CO2, metano, N2O) desde la quema de combustibles f√≥siles, deforestaci√≥n y ganader√≠a intensiva. "
            "Estos gases atrapan calor en la atm√≥sfera. Sus consecuencias incluyen aumento del nivel del mar, eventos clim√°ticos extremos m√°s frecuentes, "
            "p√©rdida de biodiversidad y disrupciones en la producci√≥n agr√≠cola.",
            
            # Respuesta de referencia 4
            "Ada Lovelace fue una matem√°tica pionera que escribi√≥ el primer algoritmo pensado para la M√°quina Anal√≠tica de Babbage en 1843, "
            "gan√°ndose el t√≠tulo de primer programador del mundo. Sus notas matem√°ticas demostraban una comprensi√≥n profunda de la l√≥gica computacional "
            "y anticiparon conceptos modernos de programaci√≥n como loops y funciones m√°s de un siglo antes de que existieran computadoras electr√≥nicas.",
            
            # Respuesta de referencia 5
            "El ejercicio regular mejora la salud cardiovascular, fuerza muscular y flexibilidad, mientras reduce significativamente el riesgo de "
            "enfermedades cr√≥nicas como diabetes, hipertensi√≥n y ciertos c√°nceres. Psicol√≥gicamente, reduce estr√©s y depresi√≥n, mejora el estado de √°nimo "
            "mediante endorfinas y fortalece la funci√≥n cognitiva. Se recomienda 150 minutos de actividad aer√≥bica moderada por semana m√°s ejercicios de resistencia."
        ]
    }
    
    return dataset


# ============================================================================
# EJERCICIO 2: Evaluar con Faithfulness
# ============================================================================

def generate_responses_with_llm(dataset: Dict[str, List[str]]) -> List[str]:
    """
    Genera respuestas usando OpenAI para cada pregunta con su contexto
    
    El LLM debe responder BAS√ÅNDOSE √öNICAMENTE en el contexto proporcionado
    """
    client = OpenAI(api_key=OPENAI_API_KEY)
    generated_responses = []
    
    print("\nü§ñ GENERANDO RESPUESTAS CON LLM...\n")
    
    for i, (question, contexts, _) in enumerate(zip(
        dataset["questions"],
        dataset["contexts"],
        dataset["answers"]
    ), 1):
        context_text = " ".join(contexts)
        
        prompt = f"""Bas√°ndote √öNICAMENTE en el siguiente contexto, responde la pregunta de manera clara y precisa.

CONTEXTO:
{context_text}

PREGUNTA: {question}

RESPUESTA:"""
        
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un asistente que responde preguntas bas√°ndote √∫nicamente en el contexto proporcionado. "
                                   "No hagas inferencias ni agregues informaci√≥n externa. S√© preciso y conciso."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=300
            )
            
            generated_response = response.choices[0].message.content.strip()
            generated_responses.append(generated_response)
            print(f"‚úÖ Pregunta {i} procesada")
            
        except Exception as e:
            print(f"‚ùå Error en pregunta {i}: {str(e)}")
            generated_responses.append("")
    
    return generated_responses


def evaluate_faithfulness(
    dataset: Dict[str, List[str]],
    generated_responses: List[str]
) -> pd.DataFrame:
    """
    Eval√∫a Faithfulness: qu√© tan fiel es la respuesta al contexto proporcionado
    
    Faithfulness mide si la respuesta se basa √öNICAMENTE en el contexto,
    sin agregar hechos no verificables o alucinar informaci√≥n.
    """
    client = OpenAI(api_key=OPENAI_API_KEY)
    faithfulness_scores = []
    
    print("\nüìä EVALUANDO FAITHFULNESS...\n")
    
    for i, (question, context, reference_answer, generated_response) in enumerate(zip(
        dataset["questions"],
        dataset["contexts"],
        dataset["answers"],
        generated_responses
    ), 1):
        context_text = " ".join(context)
        
        evaluation_prompt = f"""Eval√∫a la FAITHFULNESS (fidelidad al contexto) de la siguiente respuesta.

CONTEXTO PROPORCIONADO:
{context_text}

PREGUNTA:
{question}

RESPUESTA GENERADA A EVALUAR:
{generated_response}

Determina si la respuesta:
1. Se basa √öNICAMENTE en el contexto (sin informaci√≥n externa)
2. No contiene alucinaciones o hechos no verificables en el contexto
3. Es coherente con la informaci√≥n proporcionada

Proporciona:
1. Score de 0 a 1 donde:
   - 1.0 = La respuesta se basa completamente en el contexto, sin alucinaciones
   - 0.75 = La respuesta es mayormente fiel al contexto con m√≠nimos desv√≠os
   - 0.5 = La respuesta mezcla informaci√≥n del contexto con afirmaciones externas
   - 0.25 = La respuesta contiene m√°s informaci√≥n no verificable que del contexto
   - 0.0 = La respuesta es principalmente alucinada/no verificable

2. Breve explicaci√≥n de por qu√© merece ese score

Responde EXACTAMENTE en este formato:
SCORE: <n√∫mero entre 0 y 1>
EXPLICACI√ìN: <texto>"""
        
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un evaluador experto en calidad de texto y fidelidad a contextos. "
                                   "Tu tarea es evaluar si las respuestas est√°n fundamentadas en el contexto proporcionado."
                    },
                    {"role": "user", "content": evaluation_prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )
            
            evaluation_text = response.choices[0].message.content.strip()
            
            # Parse score
            score = 0.5
            score_line = [line for line in evaluation_text.split("\n") if "SCORE:" in line]
            if score_line:
                score_str = score_line[0].replace("SCORE:", "").strip()
                try:
                    score = float(score_str)
                    score = max(0, min(1, score))  # Clamp entre 0 y 1
                except ValueError:
                    score = 0.5
            
            # Parse explanation
            explanation = "N/A"
            explanation_line = [line for line in evaluation_text.split("\n") if "EXPLICACI√ìN:" in line]
            if explanation_line:
                explanation = explanation_line[0].replace("EXPLICACI√ìN:", "").strip()
            
            faithfulness_scores.append({
                "Pregunta #": i,
                "Score Faithfulness": round(score, 2),
                "Explicaci√≥n": explanation,
                "Respuesta Generada": generated_response[:100] + "..."
            })
            
            print(f"‚úÖ Evaluaci√≥n pregunta {i}: {score:.2f}")
            
        except Exception as e:
            print(f"‚ùå Error evaluando pregunta {i}: {str(e)}")
            faithfulness_scores.append({
                "Pregunta #": i,
                "Score Faithfulness": 0.0,
                "Explicaci√≥n": f"Error en evaluaci√≥n: {str(e)}",
                "Respuesta Generada": generated_response[:100] + "..."
            })
    
    df = pd.DataFrame(faithfulness_scores)
    return df


# ============================================================================
# EJERCICIO 3: M√©trica Personalizada - Completitud de Respuesta
# ============================================================================

def evaluate_completeness(
    dataset: Dict[str, List[str]],
    generated_responses: List[str]
) -> pd.DataFrame:
    """
    M√âTRICA PERSONALIZADA: Completitud de Respuesta
    
    Eval√∫a si la respuesta cubre TODOS los aspectos principales preguntados.
    Compara la respuesta generada contra la respuesta de referencia (ground truth).
    
    Score 0-1 basado en cobertura de informaci√≥n clave.
    """
    client = OpenAI(api_key=OPENAI_API_KEY)
    completeness_scores = []
    
    print("\nüìã EVALUANDO COMPLETITUD (M√âTRICA PERSONALIZADA)...\n")
    
    for i, (question, context, reference_answer, generated_response) in enumerate(zip(
        dataset["questions"],
        dataset["contexts"],
        dataset["answers"],
        generated_responses
    ), 1):
        context_text = " ".join(context)
        
        evaluation_prompt = f"""Eval√∫a la COMPLETITUD de la siguiente respuesta generada.

PREGUNTA:
{question}

RESPUESTA DE REFERENCIA (ground truth):
{reference_answer}

RESPUESTA GENERADA A EVALUAR:
{generated_response}

Tu tarea: Determinar si la respuesta generada cubre TODOS los puntos clave presentes en la respuesta de referencia.

Proporciona:
1. Score de 0 a 1 donde:
   - 1.0 = Cubre todos los puntos clave de la respuesta de referencia
   - 0.75 = Cubre la mayor√≠a de puntos clave (90%+)
   - 0.5 = Cubre aproximadamente la mitad de los puntos clave
   - 0.25 = Cubre pocos puntos clave (menos del 25%)
   - 0.0 = No cubre puntos clave relevantes o respuesta vac√≠a

2. Lista de puntos CUBIERTOS (presentes en la respuesta generada)
3. Lista de puntos FALTANTES (presentes en referencia pero no en generada)

Responde EXACTAMENTE en este formato:
SCORE: <n√∫mero entre 0 y 1>
PUNTOS_CUBIERTOS: <lista separada por comas>
PUNTOS_FALTANTES: <lista separada por comas>
AN√ÅLISIS: <breve explicaci√≥n>"""
        
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un evaluador experto en completitud y cobertura de respuestas. "
                                   "Comparas respuestas generadas contra respuestas de referencia para evaluar qu√© tan completas son."
                    },
                    {"role": "user", "content": evaluation_prompt}
                ],
                temperature=0.3,
                max_tokens=300
            )
            
            evaluation_text = response.choices[0].message.content.strip()
            
            # Parse score
            score = 0.5
            score_line = [line for line in evaluation_text.split("\n") if "SCORE:" in line]
            if score_line:
                try:
                    score = float(score_line[0].replace("SCORE:", "").strip())
                    score = max(0, min(1, score))
                except ValueError:
                    score = 0.5
            
            # Parse cubiertos
            cubiertos = "N/A"
            cubiertos_line = [line for line in evaluation_text.split("\n") if "PUNTOS_CUBIERTOS:" in line]
            if cubiertos_line:
                cubiertos = cubiertos_line[0].replace("PUNTOS_CUBIERTOS:", "").strip()
            
            # Parse faltantes
            faltantes = "N/A"
            faltantes_line = [line for line in evaluation_text.split("\n") if "PUNTOS_FALTANTES:" in line]
            if faltantes_line:
                faltantes = faltantes_line[0].replace("PUNTOS_FALTANTES:", "").strip()
            
            completeness_scores.append({
                "Pregunta #": i,
                "Score Completitud": round(score, 2),
                "Puntos Cubiertos": cubiertos[:80] + "...",
                "Puntos Faltantes": faltantes[:80] + "...",
                "Pregunta": question[:60] + "..."
            })
            
            print(f"‚úÖ Completitud pregunta {i}: {score:.2f}")
            
        except Exception as e:
            print(f"‚ùå Error evaluando pregunta {i}: {str(e)}")
            completeness_scores.append({
                "Pregunta #": i,
                "Score Completitud": 0.0,
                "Puntos Cubiertos": f"Error: {str(e)}",
                "Puntos Faltantes": "N/A",
                "Pregunta": question[:60] + "..."
            })
    
    return pd.DataFrame(completeness_scores)


# ============================================================================
# Funciones Auxiliares - Visualizaci√≥n y Reportes
# ============================================================================

def visualize_results(faithfulness_df: pd.DataFrame, completeness_df: pd.DataFrame):
    """
    Crea visualizaciones de los resultados de evaluaci√≥n
    """
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Gr√°fico 1: Scores Faithfulness
    axes[0].bar(faithfulness_df["Pregunta #"], faithfulness_df["Score Faithfulness"], color='steelblue')
    axes[0].axhline(y=faithfulness_df["Score Faithfulness"].mean(), color='red', linestyle='--', label='Promedio')
    axes[0].set_xlabel("N√∫mero de Pregunta")
    axes[0].set_ylabel("Score Faithfulness")
    axes[0].set_title("Evaluaci√≥n de Faithfulness por Pregunta")
    axes[0].set_ylim([0, 1])
    axes[0].legend()
    axes[0].grid(axis='y', alpha=0.3)
    
    # Gr√°fico 2: Scores Completitud
    axes[1].bar(completeness_df["Pregunta #"], completeness_df["Score Completitud"], color='seagreen')
    axes[1].axhline(y=completeness_df["Score Completitud"].mean(), color='red', linestyle='--', label='Promedio')
    axes[1].set_xlabel("N√∫mero de Pregunta")
    axes[1].set_ylabel("Score Completitud")
    axes[1].set_title("Evaluaci√≥n de Completitud por Pregunta")
    axes[1].set_ylim([0, 1])
    axes[1].legend()
    axes[1].grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('evaluation_results.png', dpi=300, bbox_inches='tight')
    print("‚úÖ Gr√°fico guardado en: evaluation_results.png")
    plt.close()


def generate_report(
    dataset: Dict[str, List[str]],
    generated_responses: List[str],
    faithfulness_df: pd.DataFrame,
    completeness_df: pd.DataFrame
):
    """
    Genera un reporte detallado en formato texto
    """
    report = f"""
================================================================================
                    üìä REPORTE FINAL - LAB 8: EVALUACI√ìN DE IA
================================================================================

FECHA: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

================================================================================
1. RESUMEN DATASET
================================================================================
Total de pares (pregunta, contexto, respuesta referencia): {len(dataset['questions'])}
Temas cubiertos: Historia, Biolog√≠a, Ciencia, Tecnolog√≠a, Salud

================================================================================
2. RESULTADOS FAITHFULNESS (Ejercicio 2)
================================================================================

M√©trica: ¬øQu√© tan fiel es la respuesta al contexto proporcionado?
Rango: 0.0 (completamente alucinada) a 1.0 (100% fiel al contexto)

"""
    
    report += faithfulness_df.to_string(index=False) + "\n\n"
    
    report += f"""
üìà ESTAD√çSTICAS FAITHFULNESS:
   - Score Promedio: {faithfulness_df['Score Faithfulness'].mean():.2f}
   - Score M√°ximo: {faithfulness_df['Score Faithfulness'].max():.2f}
   - Score M√≠nimo: {faithfulness_df['Score Faithfulness'].min():.2f}
   - Desviaci√≥n Est√°ndar: {faithfulness_df['Score Faithfulness'].std():.2f}

================================================================================
3. RESULTADOS COMPLETITUD (Ejercicio 3 - M√âTRICA PERSONALIZADA)
================================================================================

M√©trica: ¬øLa respuesta cubre todos los aspectos preguntados?
Tipo: M√©trica Personalizada - Comparaci√≥n contra respuesta de referencia
Rango: 0.0 (no cubre nada) a 1.0 (cubre todos los puntos clave)

"""
    
    report += completeness_df.to_string(index=False) + "\n\n"
    
    report += f"""
üìà ESTAD√çSTICAS COMPLETITUD:
   - Score Promedio: {completeness_df['Score Completitud'].mean():.2f}
   - Score M√°ximo: {completeness_df['Score Completitud'].max():.2f}
   - Score M√≠nimo: {completeness_df['Score Completitud'].min():.2f}
   - Desviaci√≥n Est√°ndar: {completeness_df['Score Completitud'].std():.2f}

================================================================================
4. AN√ÅLISIS COMPARATIVO
================================================================================

Correlaci√≥n Faithfulness vs Completitud: 
{faithfulness_df['Score Faithfulness'].corr(completeness_df['Score Completitud']):.2f}

Interpretaci√≥n:
- Si es alto (>0.6): Respuestas fieles tienden a ser m√°s completas
- Si es bajo (<0.3): No hay relaci√≥n entre fidelidad y completitud

================================================================================
5. RECOMENDACIONES
================================================================================

A) Preguntas con baja Faithfulness (< 0.6):
"""
    
    low_faithfulness = faithfulness_df[faithfulness_df['Score Faithfulness'] < 0.6]
    if len(low_faithfulness) > 0:
        for idx, row in low_faithfulness.iterrows():
            report += f"\n   - Pregunta {row['Pregunta #']}: {row['Explicaci√≥n']}"
    else:
        report += "\n   ‚úÖ Todas las respuestas tienen buena fidelidad al contexto"
    
    report += "\n\nB) Preguntas con baja Completitud (< 0.6):\n"
    
    low_completeness = completeness_df[completeness_df['Score Completitud'] < 0.6]
    if len(low_completeness) > 0:
        for idx, row in low_completeness.iterrows():
            report += f"\n   - Pregunta {row['Pregunta #']}: Puntos faltantes: {row['Puntos Faltantes']}"
    else:
        report += "\n   ‚úÖ Todas las respuestas cubren bien los puntos clave"
    
    report += """

================================================================================
6. METODOLOG√çA
================================================================================

EJERCICIO 1 - Dataset:
‚úÖ Creaci√≥n de dataset con 5 pares de (pregunta, contexto, respuesta referencia)
‚úÖ Contextos suficientemente informativos para responder correctamente
‚úÖ Preguntas claras y bien formuladas
‚úÖ Respuestas de referencia precisas y completas
‚úÖ Coherencia entre pregunta, contexto y respuesta

EJERCICIO 2 - Faithfulness (RAGAS):
‚úÖ Instalaci√≥n de RAGAS framework
‚úÖ Generaci√≥n de respuestas con LLM (GPT-4o-mini)
‚úÖ C√°lculo de m√©trica Faithfulness para cada respuesta
‚úÖ An√°lisis de alucinaciones y fidelidad al contexto

EJERCICIO 3 - M√©trica Personalizada:
‚úÖ Tipo elegido: Completitud de Respuesta
‚úÖ Compara respuesta generada vs respuesta de referencia
‚úÖ Eval√∫a cobertura de puntos clave
‚úÖ Score autom√°tico basado en an√°lisis de contenido
‚úÖ Validaci√≥n manual contra m√∫ltiples respuestas

================================================================================
7. ARCHIVOS GENERADOS
================================================================================

- faithfulness_results.csv     : Resultados detallados de Faithfulness
- completeness_results.csv     : Resultados detallados de Completitud
- evaluation_results.png       : Visualizaci√≥n de scores por pregunta
- evaluation_report.txt        : Este reporte

================================================================================
                                FIN DEL REPORTE
================================================================================
"""
    
    return report


# ============================================================================
# Funci√≥n Principal
# ============================================================================

def main():
    print("=" * 80)
    print("üß™ LAB 8: EVALUACI√ìN DE MODELOS DE IA")
    print("=" * 80)
    
    # ========================================================================
    # EJERCICIO 1: Crear Dataset Personalizado
    # ========================================================================
    print("\nüìå EJERCICIO 1: Crear Dataset Personalizado")
    print("-" * 80)
    
    dataset = create_custom_dataset()
    print(f"‚úÖ Dataset creado con {len(dataset['questions'])} pares pregunta-respuesta")
    print("\nPreguntas en el dataset:")
    for i, q in enumerate(dataset['questions'], 1):
        print(f"   {i}. {q}")
    
    # ========================================================================
    # EJERCICIO 2: Evaluar Faithfulness
    # ========================================================================
    print("\nüìä EJERCICIO 2: Evaluar Faithfulness de RAGAS")
    print("-" * 80)
    
    # Generar respuestas
    generated_responses = generate_responses_with_llm(dataset)
    
    # Evaluar Faithfulness
    faithfulness_df = evaluate_faithfulness(dataset, generated_responses)
    
    print("\nüìà RESULTADOS FAITHFULNESS:")
    print(faithfulness_df.to_string(index=False))
    print(f"\nüìä Score promedio Faithfulness: {faithfulness_df['Score Faithfulness'].mean():.2f}")
    print(f"   (Rango: {faithfulness_df['Score Faithfulness'].min():.2f} - {faithfulness_df['Score Faithfulness'].max():.2f})")
    
    # Guardar resultados
    faithfulness_df.to_csv("faithfulness_results.csv", index=False)
    print("\n‚úÖ Resultados guardados en: faithfulness_results.csv")
    
    # ========================================================================
    # EJERCICIO 3: M√©trica Personalizada - Completitud
    # ========================================================================
    print("\nüìã EJERCICIO 3: M√©trica Personalizada - Completitud de Respuesta")
    print("-" * 80)
    print("Tipo de m√©trica: Completitud - ¬øCubre todos los aspectos preguntados?")
    print("Comparaci√≥n: Respuesta generada vs Respuesta de referencia (ground truth)")
    
    completeness_df = evaluate_completeness(dataset, generated_responses)
    
    print("\nüìà RESULTADOS COMPLETITUD:")
    print(completeness_df.to_string(index=False))
    print(f"\nüìä Score promedio Completitud: {completeness_df['Score Completitud'].mean():.2f}")
    print(f"   (Rango: {completeness_df['Score Completitud'].min():.2f} - {completeness_df['Score Completitud'].max():.2f})")
    
    # Guardar resultados
    completeness_df.to_csv("completeness_results.csv", index=False)
    print("\n‚úÖ Resultados guardados en: completeness_results.csv")
    
    # ========================================================================
    # Visualizaci√≥n y Reporte Final
    # ========================================================================
    print("\nüìä Generando visualizaciones...")
    visualize_results(faithfulness_df, completeness_df)
    
    print("\nüìù Generando reporte final...")
    report = generate_report(dataset, generated_responses, faithfulness_df, completeness_df)
    
    with open("evaluation_report.txt", "w", encoding="utf-8") as f:
        f.write(report)
    
    print("‚úÖ Reporte guardado en: evaluation_report.txt")
    
    # ========================================================================
    # Resumen Final
    # ========================================================================
    print("\n" + "=" * 80)
    print("üéØ RESUMEN FINAL")
    print("=" * 80)
    print(f"\n‚úÖ EJERCICIO 1 - Dataset:")
    print(f"   ‚Ä¢ Total de pares: {len(dataset['questions'])}")
    print(f"   ‚Ä¢ Contextos detallados y precisos: ‚úÖ")
    print(f"   ‚Ä¢ Respuestas de referencia: ‚úÖ")
    
    print(f"\n‚úÖ EJERCICIO 2 - Faithfulness:")
    print(f"   ‚Ä¢ Score promedio: {faithfulness_df['Score Faithfulness'].mean():.2f}")
    print(f"   ‚Ä¢ Respuestas muy fieles: {len(faithfulness_df[faithfulness_df['Score Faithfulness'] >= 0.8])} de {len(faithfulness_df)}")
    
    print(f"\n‚úÖ EJERCICIO 3 - Completitud (M√©trica Personalizada):")
    print(f"   ‚Ä¢ Score promedio: {completeness_df['Score Completitud'].mean():.2f}")
    print(f"   ‚Ä¢ Respuestas muy completas: {len(completeness_df[completeness_df['Score Completitud'] >= 0.8])} de {len(completeness_df)}")
    
    print(f"\nüìÅ Archivos generados:")
    print(f"   ‚Ä¢ faithfulness_results.csv")
    print(f"   ‚Ä¢ completeness_results.csv")
    print(f"   ‚Ä¢ evaluation_results.png")
    print(f"   ‚Ä¢ evaluation_report.txt")
    
    print("\n" + "=" * 80)
    print("‚ú® ¬°LABORATORIO COMPLETADO EXITOSAMENTE! ‚ú®")
    print("=" * 80)


if __name__ == "__main__":
    main()
