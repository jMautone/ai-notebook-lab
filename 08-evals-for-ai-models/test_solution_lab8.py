"""
test_solution_lab8.py

Script de testing para verificar que la soluci√≥n funciona correctamente
sin necesidad de hacer llamadas a la API (simula respuestas).
"""

import os
import sys
from typing import Dict, List
import pandas as pd

def test_imports():
    """Test 1: Verificar que todas las librer√≠as necesarias est√°n disponibles"""
    print("\n" + "="*70)
    print("TEST 1: Verificar Importaciones")
    print("="*70)
    
    try:
        import openai
        print("‚úÖ openai disponible")
    except ImportError:
        print("‚ùå openai NO disponible - ejecuta: pip install openai")
        return False
    
    try:
        import pandas
        print("‚úÖ pandas disponible")
    except ImportError:
        print("‚ùå pandas NO disponible - ejecuta: pip install pandas")
        return False
    
    try:
        import matplotlib
        print("‚úÖ matplotlib disponible")
    except ImportError:
        print("‚ùå matplotlib NO disponible - ejecuta: pip install matplotlib")
        return False
    
    try:
        from dotenv import load_dotenv
        print("‚úÖ python-dotenv disponible")
    except ImportError:
        print("‚ùå python-dotenv NO disponible - ejecuta: pip install python-dotenv")
        return False
    
    return True


def test_env_file():
    """Test 2: Verificar que existe archivo .env"""
    print("\n" + "="*70)
    print("TEST 2: Verificar Archivo .env")
    print("="*70)
    
    env_path = ".env"
    
    if not os.path.exists(env_path):
        print(f"‚ùå No existe archivo {env_path}")
        print(f"   Crea {env_path} con tu API key")
        return False
    
    print(f"‚úÖ Archivo {env_path} existe")
    
    # Verificar que tiene contenido
    try:
        from dotenv import load_dotenv
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            print("‚ö†Ô∏è  OPENAI_API_KEY no configurada en .env")
            print("   Edita .env y agrega: OPENAI_API_KEY=sk-proj-tu-clave")
            return False
        
        if api_key.startswith("sk-proj-"):
            print("‚úÖ OPENAI_API_KEY est√° configurada (formato v√°lido)")
            return True
        else:
            print("‚ö†Ô∏è  OPENAI_API_KEY no tiene formato de OpenAI")
            print("   Debe empezar con: sk-proj-")
            return False
            
    except Exception as e:
        print(f"‚ùå Error leyendo .env: {str(e)}")
        return False


def test_dataset_structure():
    """Test 3: Verificar estructura del dataset"""
    print("\n" + "="*70)
    print("TEST 3: Estructura del Dataset")
    print("="*70)
    
    try:
        from solution_lab8 import create_custom_dataset
        
        dataset = create_custom_dataset()
        
        # Verificar claves
        required_keys = {"questions", "contexts", "answers"}
        actual_keys = set(dataset.keys())
        
        if required_keys != actual_keys:
            print(f"‚ùå Keys incorrectas. Esperado: {required_keys}, Actual: {actual_keys}")
            return False
        
        print("‚úÖ Claves correctas: questions, contexts, answers")
        
        # Verificar cantidad de pares
        num_questions = len(dataset["questions"])
        num_contexts = len(dataset["contexts"])
        num_answers = len(dataset["answers"])
        
        if num_questions != num_contexts or num_questions != num_answers:
            print(f"‚ùå Cantidad inconsistente: Q={num_questions}, C={num_contexts}, A={num_answers}")
            return False
        
        if num_questions < 5:
            print(f"‚ùå Requiere m√≠nimo 5 pares, tiene {num_questions}")
            return False
        
        print(f"‚úÖ Dataset tiene {num_questions} pares")
        
        # Verificar contenido
        for i in range(num_questions):
            q = dataset["questions"][i]
            c = dataset["contexts"][i]
            a = dataset["answers"][i]
            
            if not isinstance(q, str) or len(q) == 0:
                print(f"‚ùå Pregunta {i} inv√°lida")
                return False
            
            if not isinstance(c, list) or len(c) == 0:
                print(f"‚ùå Contexto {i} inv√°lido (debe ser lista)")
                return False
            
            if not isinstance(a, str) or len(a) == 0:
                print(f"‚ùå Respuesta {i} inv√°lida")
                return False
            
            # Verificar longitud de contexto
            context_length = sum(len(ctx) for ctx in c)
            if context_length < 100:
                print(f"‚ö†Ô∏è  Contexto {i} muy corto ({context_length} caracteres)")
        
        print("‚úÖ Todas las preguntas, contextos y respuestas v√°lidas")
        return True
        
    except Exception as e:
        print(f"‚ùå Error en dataset: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_functions_exist():
    """Test 4: Verificar que todas las funciones existen"""
    print("\n" + "="*70)
    print("TEST 4: Funciones Requeridas")
    print("="*70)
    
    try:
        from solution_lab8 import (
            create_custom_dataset,
            generate_responses_with_llm,
            evaluate_faithfulness,
            evaluate_completeness,
            visualize_results,
            generate_report
        )
        
        functions = [
            ("create_custom_dataset", create_custom_dataset),
            ("generate_responses_with_llm", generate_responses_with_llm),
            ("evaluate_faithfulness", evaluate_faithfulness),
            ("evaluate_completeness", evaluate_completeness),
            ("visualize_results", visualize_results),
            ("generate_report", generate_report),
        ]
        
        for name, func in functions:
            if callable(func):
                print(f"‚úÖ {name}() existe y es callable")
            else:
                print(f"‚ùå {name}() no es callable")
                return False
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Error importando funciones: {str(e)}")
        return False


def test_mock_evaluation():
    """Test 5: Simular flujo de evaluaci√≥n sin API calls"""
    print("\n" + "="*70)
    print("TEST 5: Flujo de Evaluaci√≥n (Mock - sin API)")
    print("="*70)
    
    try:
        from solution_lab8 import create_custom_dataset
        
        dataset = create_custom_dataset()
        
        # Crear respuestas simuladas
        mock_responses = [
            "La Revoluci√≥n Industrial transform√≥ la manufactura mediante mecanizaci√≥n.",
            "La fotos√≠ntesis convierte luz, agua y CO2 en glucosa y ox√≠geno.",
            "El cambio clim√°tico es el aumento de temperaturas por emisiones humanas.",
            "Ada Lovelace escribi√≥ el primer algoritmo en 1843 para m√°quinas.",
            "El ejercicio mejora la salud cardiovascular y mental significativamente."
        ]
        
        if len(mock_responses) != len(dataset["questions"]):
            print("‚ùå Cantidad de respuestas mockeadas incorrecta")
            return False
        
        # Simular creaci√≥n de DataFrames
        data = {
            "Pregunta #": list(range(1, len(mock_responses) + 1)),
            "Score": [0.85, 0.80, 0.75, 0.90, 0.88],
            "Explicaci√≥n": ["Mock"] * len(mock_responses)
        }
        
        df = pd.DataFrame(data)
        
        if len(df) != len(dataset["questions"]):
            print(f"‚ùå DataFrame tiene tama√±o incorrecto")
            return False
        
        print(f"‚úÖ Flujo de evaluaci√≥n funciona (DataFrame con {len(df)} registros)")
        print(f"   Columnas: {', '.join(df.columns.tolist())}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en flujo mock: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_file_structure():
    """Test 6: Verificar estructura de archivos"""
    print("\n" + "="*70)
    print("TEST 6: Estructura de Archivos")
    print("="*70)
    
    required_files = [
        ("solution_lab8.py", "C√≥digo principal"),
        (".env", "Configuraci√≥n (crear si no existe)"),
        ("requirements.txt", "Dependencias"),
        ("README.md", "Documentaci√≥n"),
    ]
    
    all_ok = True
    for filename, description in required_files:
        if os.path.exists(filename):
            size = os.path.getsize(filename)
            print(f"‚úÖ {filename} ({size} bytes) - {description}")
        else:
            if filename == ".env":
                print(f"‚ö†Ô∏è  {filename} no existe - crea uno con tu API key")
            else:
                print(f"‚ùå {filename} no existe - {description}")
                all_ok = False
    
    return all_ok


def test_requirements():
    """Test 7: Verificar que requirements.txt est√° bien formado"""
    print("\n" + "="*70)
    print("TEST 7: Archivo Requirements.txt")
    print("="*70)
    
    if not os.path.exists("requirements.txt"):
        print("‚ö†Ô∏è  No existe requirements.txt")
        return True
    
    try:
        with open("requirements.txt", "r") as f:
            requirements = f.read().strip().split("\n")
        
        print(f"‚úÖ requirements.txt contiene {len(requirements)} dependencias:")
        for req in requirements:
            if req.strip():
                print(f"   - {req.strip()}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error leyendo requirements.txt: {str(e)}")
        return False


def main():
    """Ejecutar todos los tests"""
    
    print("\n" + "="*70)
    print("üß™ TESTING SUITE - LAB 8 SOLUTION")
    print("="*70)
    
    tests = [
        ("Importaciones", test_imports),
        ("Archivo .env", test_env_file),
        ("Estructura Dataset", test_dataset_structure),
        ("Funciones Requeridas", test_functions_exist),
        ("Flujo Mock", test_mock_evaluation),
        ("Estructura Archivos", test_file_structure),
        ("Requirements.txt", test_requirements),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\n‚ùå Error en {test_name}: {str(e)}")
            results.append((test_name, False))
    
    # Resumen
    print("\n" + "="*70)
    print("üìä RESUMEN DE TESTS")
    print("="*70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status}: {test_name}")
    
    print(f"\n{passed}/{total} tests pasados")
    
    if passed == total:
        print("\n" + "="*70)
        print("‚ú® ¬°TODOS LOS TESTS PASARON! ‚ú®")
        print("="*70)
        print("\nüöÄ Pr√≥ximo paso: Ejecuta")
        print("   python solution_lab8.py")
        print("\n(Aseg√∫rate de tener tu OPENAI_API_KEY configurada en .env)")
        return 0
    else:
        print("\n" + "="*70)
        print("‚ö†Ô∏è  ALGUNOS TESTS FALLARON")
        print("="*70)
        print("\nRevisa los errores arriba y corr√≠gelos antes de ejecutar.")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
