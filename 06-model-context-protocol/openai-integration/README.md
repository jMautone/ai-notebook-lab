# Parte 3: OpenAI Integration

## ğŸ“‹ DescripciÃ³n

Esta implementaciÃ³n integra **OpenAI GPT-4o-mini** con herramientas MCP desplegadas en **FastMCP Cloud**, permitiendo que el modelo use funciones personalizadas mediante function calling.

---

## ğŸ“ Estructura del Proyecto

```
06-model-context-protocol/
â””â”€â”€ openai-integration/        # Parte 3: OpenAI Integration
    â”œâ”€â”€ README.md              # Este archivo
    â”œâ”€â”€ server_fastmcp_openai.py   # Servidor MCP con count_letter_r
    â”œâ”€â”€ client_openai.py       # Cliente OpenAI con integraciÃ³n MCP
    â””â”€â”€ .env.example           # Plantilla de configuraciÃ³n
```

---

## ğŸ—ï¸ Decisiones de Arquitectura

### 1. **Herramienta MCP: count_letter_r**
- Cuenta letras 'r' (mayÃºsculas y minÃºsculas) en un texto
- **RazÃ³n**: Tarea simple pero Ãºtil para demostrar la integraciÃ³n

### 2. **Modelo: GPT-4o-mini**
- Modelo especÃ­fico requerido por el laboratorio
- **RazÃ³n**: Balance entre capacidad y costo, perfecto para function calling

### 3. **Function Calling de OpenAI**
- Usamos el patrÃ³n oficial de OpenAI para tool use
- **RazÃ³n**: Permite que GPT-4o-mini decida cuÃ¡ndo y cÃ³mo usar las herramientas

### 4. **ConversiÃ³n de esquemas MCP â†’ OpenAI**
- Transformamos `inputSchema` de MCP a `parameters` de OpenAI
- **RazÃ³n**: Compatibilidad entre ambos protocolos

### 5. **Flujo de 2 llamadas a OpenAI**
- Primera: El modelo decide usar la herramienta
- Segunda: El modelo genera respuesta con los resultados
- **RazÃ³n**: PatrÃ³n estÃ¡ndar de function calling

---

## ğŸš€ InstalaciÃ³n

### Paso 1: Instalar dependencias

```powershell
# Desde la raÃ­z del laboratorio
cd 06-model-context-protocol
pip install -r requirements.txt
```

Dependencias necesarias:
```
openai>=1.0.0
fastmcp>=0.3.0
httpx>=0.27.0
anyio>=4.0.0
```

---

## ğŸ“¤ Despliegue del Servidor

### OpciÃ³n A: Usando FastMCP CLI (Recomendado)

```powershell
cd openai-integration

# 1. Autenticar con FastMCP Cloud
fastmcp login

# 2. Desplegar el servidor con count_letter_r
fastmcp deploy server_fastmcp_openai.py

# 3. Copiar la URL y API Key que te proporciona
```

### OpciÃ³n B: Probar localmente primero

```powershell
# Ver que la herramienta funcione correctamente
python server_fastmcp_openai.py
```

**Salida esperada:**
```
ğŸ”§ Servidor MCP: Count Letter R
==================================================
'Terrarium' â†’ 3 letras 'r'
'El perro corre rÃ¡pido por el parque' â†’ 5 letras 'r'
'Refrigerador' â†’ 3 letras 'r'
'Computadora' â†’ 2 letras 'r'

âœ… Herramienta funcionando correctamente
```

---

## âš™ï¸ ConfiguraciÃ³n del Cliente

DespuÃ©s del despliegue necesitas **3 credenciales**:

1. **OpenAI API Key**: De tu cuenta en https://platform.openai.com/api-keys
2. **FastMCP Server URL**: Del despliegue (ej: `https://your-name-animal.fastmcp.app`)
3. **FastMCP API Key**: Del despliegue (ej: `fmcp_xxxxxxxxxxxxx`)

### ğŸ” ConfiguraciÃ³n Segura con Variables de Entorno

```powershell
# Configurar las 3 variables de entorno
$env:OPENAI_API_KEY = "sk-proj-xxxxxxxxxxxxx"
$env:FASTMCP_SERVER_URL = "https://tu-servidor.fastmcp.app"
$env:FASTMCP_API_KEY = "fmcp_xxxxxxxxxxxxx"

# Verificar que estÃ©n configuradas
echo $env:OPENAI_API_KEY
echo $env:FASTMCP_SERVER_URL
echo $env:FASTMCP_API_KEY
```

---

## â–¶ï¸ EjecuciÃ³n

```powershell
cd openai-integration
python client_openai.py
```

---

## ğŸ“Š Salida Esperada

```
======================================================================
ğŸš€ IntegraciÃ³n OpenAI + FastMCP
======================================================================
ğŸ¤– Modelo: gpt-4o-mini
ğŸ”— Servidor MCP: https://your-server.fastmcp.app
ğŸ”‘ OpenAI API Key: sk-proj-...
======================================================================

======================================================================
ğŸ“ Prueba 1/3
======================================================================

ğŸ’¬ Usuario: Â¿CuÃ¡ntas letras 'r' hay en la palabra 'Terrarium'?
ğŸ” Obteniendo herramientas MCP...
âœ… Herramientas encontradas: count_letter_r
ğŸ¤– Consultando a GPT-4o-mini...

ğŸ”§ Llamando a herramienta MCP: count_letter_r
   Argumentos: {'text': 'Terrarium'}
   âœ… Resultado: 3

ğŸ¤– Generando respuesta final...

âœ¨ Respuesta de GPT-4o-mini:
La palabra 'Terrarium' contiene 3 letras 'r'.

======================================================================
ğŸ“ Prueba 2/3
======================================================================

ğŸ’¬ Usuario: Cuenta las 'r' en: 'El perro corre rÃ¡pido por el parque'
ğŸ” Obteniendo herramientas MCP...
âœ… Herramientas encontradas: count_letter_r
ğŸ¤– Consultando a GPT-4o-mini...

ğŸ”§ Llamando a herramienta MCP: count_letter_r
   Argumentos: {'text': 'El perro corre rÃ¡pido por el parque'}
   âœ… Resultado: 5

ğŸ¤– Generando respuesta final...

âœ¨ Respuesta de GPT-4o-mini:
En la frase "El perro corre rÃ¡pido por el parque" hay 5 letras 'r'.

======================================================================
ğŸ“ Prueba 3/3
======================================================================

ğŸ’¬ Usuario: Â¿Hay mÃ¡s letras 'r' en 'Refrigerador' o en 'Computadora'?
ğŸ” Obteniendo herramientas MCP...
âœ… Herramientas encontradas: count_letter_r
ğŸ¤– Consultando a GPT-4o-mini...

ğŸ”§ Llamando a herramienta MCP: count_letter_r
   Argumentos: {'text': 'Refrigerador'}
   âœ… Resultado: 3

ğŸ”§ Llamando a herramienta MCP: count_letter_r
   Argumentos: {'text': 'Computadora'}
   âœ… Resultado: 2

ğŸ¤– Generando respuesta final...

âœ¨ Respuesta de GPT-4o-mini:
'Refrigerador' tiene mÃ¡s letras 'r' (3) que 'Computadora' (2).

======================================================================
âœ… Todas las pruebas completadas
======================================================================
```

---

## ğŸ” ExplicaciÃ³n del Flujo

### Cliente OpenAI (`client_openai.py`)

1. **ConfiguraciÃ³n**: Lee 3 variables de entorno (OpenAI + FastMCP)

2. **Descubrimiento de herramientas**: 
   - Llama a `tools/list` en FastMCP
   - Obtiene esquema de `count_letter_r`

3. **ConversiÃ³n de esquemas**:
   - MCP `inputSchema` â†’ OpenAI `parameters`
   - Permite que GPT-4o-mini entienda la herramienta

4. **Primera llamada a OpenAI**:
   - EnvÃ­a mensaje del usuario + herramientas disponibles
   - GPT-4o-mini decide si necesita usar `count_letter_r`

5. **EjecuciÃ³n de herramientas**:
   - Si GPT-4o-mini solicita la herramienta, la ejecutamos vÃ­a MCP
   - Parseamos respuesta SSE de FastMCP

6. **Segunda llamada a OpenAI**:
   - Enviamos resultados de la herramienta
   - GPT-4o-mini genera respuesta final en lenguaje natural

### Servidor MCP (`server_fastmcp_openai.py`)

1. **DefiniciÃ³n de herramienta**: `@mcp.tool()` decora `count_letter_r`

2. **ImplementaciÃ³n**:
   ```python
   def count_letter_r(text: str) -> int:
       return text.lower().count('r')
   ```

3. **Despliegue**: FastMCP CLI sube a la nube

---

## ğŸ”§ Detalles TÃ©cnicos

### Formato de Herramienta MCP
```json
{
  "name": "count_letter_r",
  "description": "Cuenta cuÃ¡ntas veces aparece la letra 'r'...",
  "inputSchema": {
    "type": "object",
    "properties": {
      "text": {"type": "string", "description": "La palabra o frase"}
    },
    "required": ["text"]
  }
}
```

### Formato de Herramienta OpenAI
```json
{
  "type": "function",
  "function": {
    "name": "count_letter_r",
    "description": "Cuenta cuÃ¡ntas veces aparece la letra 'r'...",
    "parameters": {
      "type": "object",
      "properties": {
        "text": {"type": "string", "description": "La palabra o frase"}
      },
      "required": ["text"]
    }
  }
}
```

---

## âœ… Criterios de Ã‰xito Cumplidos

- âœ… Servidor MCP con `count_letter_r` desplegado en FastMCP Cloud
- âœ… Cliente OpenAI configurado con `gpt-4o-mini`
- âœ… IntegraciÃ³n MCP â†” OpenAI funcional
- âœ… Function calling implementado correctamente
- âœ… Las 3 pruebas del enunciado ejecutadas exitosamente
- âœ… Respuestas precisas y en lenguaje natural

---

## ğŸ› SoluciÃ³n de Problemas

### Error: "Variable de entorno no configurada"

**SoluciÃ³n**: Configura las 3 variables requeridas:
```powershell
$env:OPENAI_API_KEY = "sk-proj-..."
$env:FASTMCP_SERVER_URL = "https://..."
$env:FASTMCP_API_KEY = "fmcp_..."
```

### Error: "Invalid API Key" (OpenAI)

**SoluciÃ³n**: 
- Verifica que tu API Key de OpenAI sea vÃ¡lida
- AsegÃºrate de tener crÃ©ditos disponibles en tu cuenta
- Visita https://platform.openai.com/api-keys

### Error: "Authentication failed" (FastMCP)

**SoluciÃ³n**:
- Verifica que el servidor estÃ© desplegado: `fastmcp list`
- Confirma que la URL y API Key sean correctas

### Error: "Tool not found"

**SoluciÃ³n**:
- AsegÃºrate de haber desplegado `server_fastmcp_openai.py`
- Verifica con: `python client_openai.py` (deberÃ­a listar las herramientas)

### Error: "Rate limit exceeded"

**SoluciÃ³n**:
- Espera unos segundos entre llamadas
- Verifica lÃ­mites de tu plan de OpenAI

---

## ğŸ“š Referencias

- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)
- [FastMCP + OpenAI Integration](https://gofastmcp.com/integrations/openai)
- [MCP Specification](https://spec.modelcontextprotocol.io/)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)

---

**Â¡Parte 3 completada! ğŸ‰**

**Has logrado:**
- âœ… Crear una herramienta MCP personalizada
- âœ… Desplegarla en la nube con FastMCP
- âœ… Integrarla con GPT-4o-mini
- âœ… Implementar function calling completo
- âœ… Probar con casos reales del enunciado

**Laboratorio 6 completo:** Has dominado el Model Context Protocol end-to-end! ğŸš€
